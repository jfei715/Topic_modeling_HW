---
title: "Topic_Modeling_HW"
format: pdf
editor: visual
---

```{r}
# install packages

# install.packages(c("tidyverse", "tm", "topicmodels", "ldatuning", "wordcloud", "quarto"))
# install.packages('tidytext')
library(tidyverse)
library(tm)
library(topicmodels)
library(ldatuning)
library(wordcloud)
library(quarto)
library(ggplot2)
library(tidytext)
```

```{r}
# load the dataset

movie_data <- read.csv("movie_plots.csv")
```

```{r}
# process text data

preprocess_text <- function(text) {
  text <- tolower(text)
  text <- removePunctuation(text)
  text <- removeNumbers(text)
  text <- removeWords(text, stopwords("english"))
  text <- stripWhitespace(text)
  return(text)
}

movie_data$Processed_Plot <- sapply(as.character(movie_data$Plot), preprocess_text)
```

```{r}
# create a corpus and Document-Term Matrix (DTM)

corpus <- Corpus(VectorSource(movie_data$Processed_Plot))
dtm <- DocumentTermMatrix(corpus, control = list(wordLengths = c(3, 15)))
```

```{r}
# determine optimal number of topics

result <- FindTopicsNumber(
  dtm,
  topics = seq(2, 20, by = 1),
  metrics = c("CaoJuan2009", "Arun2010", "Deveaud2014"),
  method = "Gibbs",
  control = list(seed = 1234)
)

FindTopicsNumber_plot(result)
```

```{r}
# fit the LDA model

optimal_k <- 5 # use the number determined from the scree plot
lda_model <- LDA(dtm, k = optimal_k, control = list(seed = 1234))
```

```{r}
# extract topics and top words

terms <- terms(lda_model, 10) # top 10 words per topic
terms
```

```{r}
# visualize top words per topic

topics <- tidy(lda_model) %>%
  group_by(topic) %>%
  top_n(10, beta) %>%
  ungroup() %>%
  arrange(topic, -beta)

ggplot(topics, aes(term, beta, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free") +
  coord_flip() +
  labs(title = "Top Words per Topic", y = "Beta", x = "Terms")

# The beta plots display the top terms and their probabilities for each topic generated by the LDA model, with the x-axis representing the beta values (term probabilities within a topic) and the y-axis listing the most representative terms. Higher beta values indicate that a term is more strongly associated with a particular topic. For instance, in Topic 1, terms like "young," "world," and "film" suggest themes of youth or global cinema, while Topic 5's "town," "sheriff," and "ranch" likely point to Westerns or action narratives. These plots help interpret each topicâ€™s semantic structure and assess the coherence of the model, guiding refinements like adjusting the number of topics (k) or improving preprocessing to ensure distinct and meaningful groupings.
```

```{r}
# create word clouds

all_text <- paste(movie_data$Processed_Plot, collapse = " ")
wordcloud(words = names(table(unlist(strsplit(all_text, " ")))),
          freq = table(unlist(strsplit(all_text, " "))),
          min.freq = 2,
          max.words = 200,
          random.order = FALSE,
          colors = brewer.pal(8, "Dark2"))
```
